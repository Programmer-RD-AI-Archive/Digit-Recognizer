diff --git a/Model/__init__.py b/Model/__init__.py
index 2117f1b..6952c40 100644
--- a/Model/__init__.py
+++ b/Model/__init__.py
@@ -19,8 +19,8 @@ from torchvision.models import *
 
 SAVE_DIR = "./dataset/data/"
 RAW_DIR = "./dataset/raw/"
-TEST_SIZE = 0.25
-EPOCHS = 100
+TEST_SIZE = 0.375
+EPOCHS = 1
 BATCH_SIZE = 32
 DEVICE = "cuda"
 PROJECT_NAME = "Digit-Recognizer-Competition"
diff --git a/Model/dataset/preproccessing.py b/Model/dataset/preproccessing.py
index bb33140..4b31994 100644
--- a/Model/dataset/preproccessing.py
+++ b/Model/dataset/preproccessing.py
@@ -4,11 +4,11 @@ from Model import *
 class PreProccessing:
     def __init__(
         self,
-        random_vertical_flip: bool = True,
-        color_jitter: bool = True,
-        random_grayscale: bool = True,
-        random_horizontal_flip: bool = True,
-        random_rotation: bool = True,
+        random_vertical_flip: bool = False,
+        color_jitter: bool = False,
+        random_grayscale: bool = False,
+        random_horizontal_flip: bool = False,
+        random_rotation: bool = False,
     ) -> None:
         self.color_jitter = color_jitter
         self.random_grayscale = random_grayscale
@@ -43,8 +43,11 @@ class PreProccessing:
             self.random_rotation_pp()
         if self.random_vertical_flip:
             self.random_vertical_flip_pp()
-        transformation = Compose(self.compose_list)
-        img = np.array(transformation(Image.fromarray(img)))
+        try:
+            transformation = Compose(self.compose_list)
+            img = np.array(transformation(Image.fromarray(img)))
+        except:
+            pass
         img = img / 255.0
         return img
 
diff --git a/Model/help_funcs.py b/Model/help_funcs.py
index 0ea06fa..6af56f0 100644
--- a/Model/help_funcs.py
+++ b/Model/help_funcs.py
@@ -5,6 +5,7 @@ from Model.metrics import *
 
 class Help_Funcs:
     def train(
+        self,
         PROJECT_NAME,
         name,
         epochs,
@@ -17,26 +18,45 @@ class Help_Funcs:
         model,
         criterion,
         optimizer,
+        labels_r,
     ):
         m = Metrics()
-        wandb.init(project=PROJECT_NAME, name=name)
+        wandb.init(
+            project=PROJECT_NAME,
+            name=name,
+            config={"device": device, "batch_size": batch_size, "epochs": epochs},
+        )
+        wandb.watch(model)
         for _ in tqdm(range(epochs)):
             for idx in range(0, len(X_train), batch_size):
-                X_batch = X_train[idx : idx + batch_size].to(device)
-                y_batch = y_train[idx : idx + batch_size].to(device)
+                X_batch = X_train[idx : idx + batch_size].float().to(device)
+                y_batch = y_train[idx : idx + batch_size].float().to(device)
                 preds = model(X_batch)
-                loss = criterion(preds)
-                optimizer.step()
-                loss.backward()
+                loss = criterion(preds, y_batch)
                 optimizer.zero_grad()
+                loss.backward()
+                optimizer.step()
+            model.eval()
             wandb.log(
                 {
                     "Accuracy Batch": m.accuracy(model, X_batch, y_batch),
                     "Loss Batch": loss.item(),
-                    "Accuracy": m.accuracy(model, X_test, y_test),
-                    "Loss": m.loss(model, X_test, y_test, criterion),
+                    "Accuracy": m.accuracy(
+                        model.to(device), X_test.to(device).float(), y_test.to(device).float()
+                    ),
+                    "Loss": m.loss(
+                        model.to(device),
+                        X_test.to(device).float(),
+                        y_test.to(device).float(),
+                        criterion,
+                    ),
                 }
             )
+            model.train()
+        # preds_imgs = m.test_images(model, labels_r, device)
+        # for pred_img in preds_imgs:
+        #     wandb.log({pred_img[0]: wandb.Image(pred_img[1])})
+        wandb.watch(model)
         wandb.finish()
         return (
             PROJECT_NAME,
diff --git a/Model/metrics.py b/Model/metrics.py
index e0c1511..c32a177 100644
--- a/Model/metrics.py
+++ b/Model/metrics.py
@@ -1,5 +1,9 @@
 """sumary_line"""
 from Model import *
+import os
+import cv2
+import torch
+import matplotlib.pyplot as plt
 
 
 class Metrics:
@@ -19,3 +23,28 @@ class Metrics:
                 correct += 1
             total += 1
         return round(correct / total, 3)
+
+    def test_images(self, model, labels_r, device):
+        model.eval()
+        with torch.no_grad():
+            for file_path in os.listdir("./Model/tests/"):
+                img = cv2.imread(f"./Model/tests/{file_path}", cv2.COLOR_BGR2GRAY)
+                img = cv2.resize(img, (28, 28))
+                img = img / 255.0
+                pred = model(torch.tensor(img).view(-1, 1, 28, 28).float().to(device))
+                print("*" * 50)
+                print(file_path)
+                print(pred)
+                pred = torch.argmax(pred)
+                print(pred)
+                print("*" * 50)
+                plt.figure(figsize=(10, 6))
+                plt.imshow(img)
+                plt.title(f"Prediction: {labels_r[int(pred)]}")
+                plt.savefig(f"./Model/preds/{file_path}")
+                plt.close()
+            preds_files = []
+            for file_path in os.listdir("./Model/preds/"):
+                preds_files.append([file_path, cv2.imread(f"./Model/preds/{file_path}")])
+        model.train()
+        return preds_files
diff --git a/Model/modelling/pytorch_imp.py b/Model/modelling/pytorch_imp.py
index a5ffcc4..49a9ec8 100644
--- a/Model/modelling/pytorch_imp.py
+++ b/Model/modelling/pytorch_imp.py
@@ -33,8 +33,8 @@ class CNN(Module):
         self.conv2batchnorm = BatchNorm2d(16)
         self.conv3 = Conv2d(16, 32, (3, 3))
         self.conv4batchnorm = BatchNorm2d(32)
-        self.conv5 = Conv2d(32, 64, (3, 3))
-        self.linear1 = Linear(64 * 3 * 3, 128)
+        self.conv5 = Conv2d(32, 64, (1, 1))
+        self.linear1 = Linear(64 * 1 * 1, 128)
         self.linear2batchnorm = BatchNorm1d(128)
         self.linear3 = Linear(128, 256)
         self.linear4batchnorm = Linear(256, 512)
@@ -48,8 +48,7 @@ class CNN(Module):
         preds = self.max_pool2d(self.activation(self.conv3(preds)))
         preds = self.max_pool2d(self.activation(self.conv4batchnorm(preds)))
         preds = self.conv5(preds)
-        print(preds.shape)
-        preds = preds.view(-1, 64 * 3 * 3)
+        preds = preds.view(-1, 64 * 1 * 1)
         preds = self.activation(self.linear1(preds))
         preds = self.activation(self.linear2batchnorm(preds))
         preds = self.activation(self.linear3(preds))
diff --git a/run.py b/run.py
index 3a0b31c..b6dcfa1 100644
--- a/run.py
+++ b/run.py
@@ -3,26 +3,31 @@ from Model import *
 print("Loading Data")
 ds = DataSet()
 X, y, classes, labels, idx, labels_r, X_train, y_train, X_test, y_test = ds.load_data()
+print(labels)
+print(labels_r)
+print(idx)
 print(len(X_train), len(X_test), len(y_train), len(y_test))
 print("Loaded Data")
 print("Creating Model")
-model = CNN().to(DEVICE)
+model = CNN(idx_of_classes=idx).to(DEVICE)
 criterion = MSELoss()
-optimizer = Adam(model.parameter(), lr=0.001)
+optimizer = Adam(model.parameters(), lr=0.001)
 print("Created Model")
 print("Training Model")
 hp = Help_Funcs()
 hp.train(
-    "BaseLine",
+    PROJECT_NAME,
+    "BaseLine CNN",
     EPOCHS,
-    X_train,
-    y_train,
-    X_test,
-    y_test,
+    X_train.view(-1, 1, 28, 28).to(DEVICE),
+    y_train.to(DEVICE),
+    X_test.view(-1, 1, 28, 28),
+    y_test.to(DEVICE),
     BATCH_SIZE,
     DEVICE,
     model,
     criterion,
     optimizer,
+    labels_r,
 )
 print("Trained Model")
